{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e30ce1628ba1b32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T15:48:02.820926Z",
     "start_time": "2025-09-25T15:47:56.396998Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install -q opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:46:39.594728Z",
     "start_time": "2025-10-02T17:46:33.481472Z"
    }
   },
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import opendatasets as od\n",
    "import random\n",
    "import mlflow\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "# Random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "49ad471192ddb720",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:25.984745Z",
     "start_time": "2025-10-02T17:47:25.975707Z"
    }
   },
   "source": [
    "# Import the dataset\n",
    "od.download(\"https://www.kaggle.com/datasets/laotse/credit-risk-dataset/data\",\n",
    "    data_dir=\"..\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"..\\credit-risk-dataset\" (use force=True to force download)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "81664b998672e134",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:26.382722Z",
     "start_time": "2025-10-02T17:47:26.321273Z"
    }
   },
   "source": [
    "# Define the path to the dataset\n",
    "csv_path = os.path.join(\"..\", \"credit-risk-dataset\", \"credit_risk_dataset.csv\")\n",
    "df = pd.read_csv(csv_path)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "7e021ca418fd6235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:26.512162Z",
     "start_time": "2025-10-02T17:47:26.497620Z"
    }
   },
   "source": [
    "# View the data and drop the missing values\n",
    "df.head()\n",
    "df = df.dropna()"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "cca09276-80dd-4b1c-863d-19e77cd4b992",
   "metadata": {},
   "source": [
    "Since our objective is to create a form that a customer can fill out, we need to drop the following columns:\n",
    "\n",
    "    - loan_grade - this is something our team will evaluate.\n",
    "    - loan_int_rate - not something that a customer should be able to choose arbitrarily.\n",
    "    - loan_percvent_income - can be calculated from person_income and loan_amnt.\n",
    "    - cb_person_cred_hist_length - we drop this for simplicity of the model and to make the form shorter."
   ]
  },
  {
   "cell_type": "code",
   "id": "6973d218e9da5638",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:27.156972Z",
     "start_time": "2025-10-02T17:47:27.145235Z"
    }
   },
   "source": [
    "df = df.drop(columns=[\"loan_grade\", \"loan_int_rate\", \"loan_percent_income\", \"cb_person_cred_hist_length\"])"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "8a9d95f1-aa24-42c5-8726-31220d36f49b",
   "metadata": {},
   "source": [
    "We want to have entries of cb_person_default_on_file as either 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "id": "a972a17285d7afb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:27.635732Z",
     "start_time": "2025-10-02T17:47:27.629117Z"
    }
   },
   "source": [
    "# Map yes/no to 0/1\n",
    "def yn_to01(s):\n",
    "    m = s.astype(str).str.strip().str.lower()\n",
    "    return m.map({\"y\":1,\"n\":0}).astype(float)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "46ac962b267cd10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:27.854697Z",
     "start_time": "2025-10-02T17:47:27.835523Z"
    }
   },
   "source": [
    "df[\"cb_person_default_on_file\"] = yn_to01(df[\"cb_person_default_on_file\"])"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "23ad83f186251d06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:28.094190Z",
     "start_time": "2025-10-02T17:47:28.073545Z"
    }
   },
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0          22          59000                  RENT              123.0   \n",
       "1          21           9600                   OWN                5.0   \n",
       "2          25           9600              MORTGAGE                1.0   \n",
       "3          23          65500                  RENT                4.0   \n",
       "4          24          54400                  RENT                8.0   \n",
       "\n",
       "  loan_intent  loan_amnt  loan_status  cb_person_default_on_file  \n",
       "0    PERSONAL      35000            1                        1.0  \n",
       "1   EDUCATION       1000            0                        0.0  \n",
       "2     MEDICAL       5500            1                        0.0  \n",
       "3     MEDICAL      35000            1                        0.0  \n",
       "4     MEDICAL      35000            1                        1.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>59000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>123.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>35000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>9600</td>\n",
       "      <td>OWN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>9600</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>65500</td>\n",
       "      <td>RENT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>35000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>54400</td>\n",
       "      <td>RENT</td>\n",
       "      <td>8.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>35000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "c7809604-1b65-42cb-a485-d0a9b243e707",
   "metadata": {},
   "source": "Now we encode the person_home_ownership in hierarchical order, where we value \"own\" the most and \"other\" the least."
  },
  {
   "cell_type": "code",
   "id": "5c69fa42f58bb101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:28.557496Z",
     "start_time": "2025-10-02T17:47:28.545803Z"
    }
   },
   "source": [
    "print(df[\"person_home_ownership\"].unique())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RENT' 'OWN' 'MORTGAGE' 'OTHER']\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "c855469eea2a4e2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:28.700677Z",
     "start_time": "2025-10-02T17:47:28.693181Z"
    }
   },
   "source": [
    "# Encodes person_home_ownership accounting for the hierarchy \n",
    "def hom_own(s):\n",
    "    m = s.astype(str).str.strip().str.lower()\n",
    "    return m.map({\"other\":0,\"rent\":1, \"mortgage\":2, \"own\":3}).astype(float)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "c7f2b5e767a77c81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:29.109515Z",
     "start_time": "2025-10-02T17:47:29.093270Z"
    }
   },
   "source": [
    "df[\"person_home_ownership\"] = hom_own(df[\"person_home_ownership\"])"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "95dedb32-52f2-401e-beba-cc094291a649",
   "metadata": {},
   "source": "The order for loan_intent is not so obvious, therefore we use one-hot encoding in this case"
  },
  {
   "cell_type": "code",
   "id": "f90c68b5821d031c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:29.560496Z",
     "start_time": "2025-10-02T17:47:29.547669Z"
    }
   },
   "source": "df = pd.get_dummies(df, columns=[\"loan_intent\"], prefix=\"loan_intent\", drop_first=True, dtype=float)",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "c65a3136e098e36f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:29.811120Z",
     "start_time": "2025-10-02T17:47:29.793478Z"
    }
   },
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   person_age  person_income  person_home_ownership  person_emp_length  \\\n",
       "0          22          59000                    1.0              123.0   \n",
       "1          21           9600                    3.0                5.0   \n",
       "2          25           9600                    2.0                1.0   \n",
       "3          23          65500                    1.0                4.0   \n",
       "4          24          54400                    1.0                8.0   \n",
       "\n",
       "   loan_amnt  loan_status  cb_person_default_on_file  loan_intent_EDUCATION  \\\n",
       "0      35000            1                        1.0                    0.0   \n",
       "1       1000            0                        0.0                    1.0   \n",
       "2       5500            1                        0.0                    0.0   \n",
       "3      35000            1                        0.0                    0.0   \n",
       "4      35000            1                        1.0                    0.0   \n",
       "\n",
       "   loan_intent_HOMEIMPROVEMENT  loan_intent_MEDICAL  loan_intent_PERSONAL  \\\n",
       "0                          0.0                  0.0                   1.0   \n",
       "1                          0.0                  0.0                   0.0   \n",
       "2                          0.0                  1.0                   0.0   \n",
       "3                          0.0                  1.0                   0.0   \n",
       "4                          0.0                  1.0                   0.0   \n",
       "\n",
       "   loan_intent_VENTURE  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>59000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>35000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>9600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>9600</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>65500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>54400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "772c7b39-af3c-44aa-8f89-763201a0fa4a",
   "metadata": {},
   "source": [
    "Now it is time to train the models on this data. \n",
    "\n",
    "We will compare the baseline model (logistic regression) to a RandomForest, XGBoost, XGBoost with oversampling and a simple NN models. "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:33.577756Z",
     "start_time": "2025-10-02T17:47:30.350743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First we prepare the data for training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "X = data.drop(columns=[\"loan_status\"]).values\n",
    "y = data[\"loan_status\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ],
   "id": "8c71735453dda760",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "868dacf3498be53e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:38.846089Z",
     "start_time": "2025-10-02T17:47:36.584472Z"
    }
   },
   "source": [
    "# Baseline model\n",
    "model_baseline = LogisticRegression(class_weight=\"balanced\", max_iter=1000, solver=\"saga\")\n",
    "model_baseline.fit(X_train, y_train)\n",
    "y_pred_baseline = model_baseline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_baseline))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.72      0.78      4443\n",
      "           1       0.39      0.61      0.47      1285\n",
      "\n",
      "    accuracy                           0.69      5728\n",
      "   macro avg       0.63      0.67      0.63      5728\n",
      "weighted avg       0.76      0.69      0.71      5728\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:40.800584Z",
     "start_time": "2025-10-02T17:47:38.847839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Random Forest model\n",
    "rf_clf = RandomForestClassifier(class_weight=\"balanced\", n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ],
   "id": "1822b9752d950e1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      4443\n",
      "           1       0.85      0.54      0.66      1285\n",
      "\n",
      "    accuracy                           0.88      5728\n",
      "   macro avg       0.87      0.75      0.79      5728\n",
      "weighted avg       0.87      0.88      0.86      5728\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:41.742728Z",
     "start_time": "2025-10-02T17:47:41.019035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# XGBoost model\n",
    "xgb_clf = XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ],
   "id": "78d7b3dbeb32130c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      4443\n",
      "           1       0.86      0.57      0.68      1285\n",
      "\n",
      "    accuracy                           0.88      5728\n",
      "   macro avg       0.87      0.77      0.81      5728\n",
      "weighted avg       0.88      0.88      0.87      5728\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:51.435378Z",
     "start_time": "2025-10-02T17:47:50.539710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the data with SMOTETomek\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_train_res, y_train_res = smt.fit_resample(X_train, y_train)"
   ],
   "id": "1189149eb0158366",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:47:51.691010Z",
     "start_time": "2025-10-02T17:47:51.437978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# XGBoost with SMOTETomek\n",
    "xgb_clf_res = XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "xgb_clf_res.fit(X_train_res, y_train_res)\n",
    "y_pred_xgb_res = xgb_clf_res.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb_res))"
   ],
   "id": "8c13ea3851f4d511",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      4443\n",
      "           1       0.84      0.58      0.69      1285\n",
      "\n",
      "    accuracy                           0.88      5728\n",
      "   macro avg       0.87      0.77      0.81      5728\n",
      "weighted avg       0.88      0.88      0.87      5728\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "ff4c429df99e1ac2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:50:57.088288Z",
     "start_time": "2025-10-02T17:50:50.038479Z"
    }
   },
   "source": [
    "# Check for cuda availability\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "5c534473d247734f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:50:59.265242Z",
     "start_time": "2025-10-02T17:50:59.144212Z"
    }
   },
   "source": [
    "# Prepare the data for NN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_nn = X_train.copy()\n",
    "X_test_nn = X_test.copy()\n",
    "y_train_nn = y_train.copy()\n",
    "y_test_nn = y_test.copy()\n",
    "\n",
    "X_train_nn = scaler.fit_transform(X_train_nn)\n",
    "X_test_nn = scaler.transform(X_test_nn)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_nn = torch.tensor(X_train_nn, dtype=torch.float32).to(device)\n",
    "y_train_nn = torch.tensor(y_train_nn, dtype=torch.float32).view(-1, 1).to(device)\n",
    "X_test_nn = torch.tensor(X_test_nn, dtype=torch.float32).to(device)\n",
    "y_test_nn = torch.tensor(y_test_nn, dtype=torch.float32).view(-1, 1).to(device)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "ed49820bbdec039d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:50:59.529718Z",
     "start_time": "2025-10-02T17:50:59.511783Z"
    }
   },
   "source": [
    "# Define a simple NN model\n",
    "class CreditRiskNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model_nn = CreditRiskNN(input_dim=X_train_nn.shape[1]).to(device)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "89b66699acb1d3e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:51:09.944179Z",
     "start_time": "2025-10-02T17:50:59.988418Z"
    }
   },
   "source": [
    "# Train the NN model\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model_nn.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "epochs = 2000\n",
    "for epoch in range(epochs):\n",
    "    model_nn.train()\n",
    "    optimizer.zero_grad()\n",
    "    preds = model_nn(X_train_nn)\n",
    "    loss = criterion(preds, y_train_nn)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        model_nn.eval()\n",
    "        with torch.no_grad():\n",
    "            test_preds = (model_nn(X_test_nn) > 0.5).float()\n",
    "            acc = (test_preds.eq(y_test_nn).sum().item()) / len(y_test)\n",
    "        #print(f\"Epoch {epoch+1}/{epochs}, Loss={loss.item():.4f}, Test Acc={acc:.3f}\")\n"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:51:09.979603Z",
     "start_time": "2025-10-02T17:51:09.944179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred_nn = (model_nn(X_test_nn) > 0.5).float()\n",
    "print(classification_report(y_test_nn.cpu(), y_pred_nn.cpu()))"
   ],
   "id": "705fd2f7212821f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.98      0.92      4443\n",
      "         1.0       0.86      0.48      0.62      1285\n",
      "\n",
      "    accuracy                           0.87      5728\n",
      "   macro avg       0.86      0.73      0.77      5728\n",
      "weighted avg       0.87      0.87      0.85      5728\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we log the models and their metrics to MLflow.",
   "id": "17a0ba920ebd76e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T17:52:30.489333Z",
     "start_time": "2025-10-02T17:52:30.425296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reports = [\n",
    "    classification_report(y_test, y_pred_baseline, output_dict=True),\n",
    "    classification_report(y_test, y_pred_rf, output_dict=True),\n",
    "    classification_report(y_test, y_pred_xgb, output_dict=True),\n",
    "    classification_report(y_test, y_pred_xgb_res, output_dict=True),\n",
    "    classification_report(y_test_nn.cpu(), y_pred_nn.cpu(), output_dict=True, labels=[0,1], target_names=[\"0\", \"1\"])\n",
    "]\n",
    "\n",
    "models = [\n",
    "    [model_baseline, \"Logistic Regression\"],\n",
    "    [rf_clf, \"Random Forest\"],\n",
    "    [xgb_clf, \"XGBoost\"],\n",
    "    [xgb_clf_res, \"XGBoost with SMOTETomek\"],\n",
    "    [model_nn, \"Neural Network\"]\n",
    "]"
   ],
   "id": "de749dcdf8d2d82e",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T18:25:05.254275Z",
     "start_time": "2025-10-02T18:24:29.843650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mlflow.models import infer_signature\n",
    "\n",
    "mlflow.set_experiment(\"Credit-Default-Prediction\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "\n",
    "# Example batch for signature\n",
    "X_example = X_test[:5]\n",
    "X_example_nn = X_test[:5].astype(np.float32)\n",
    "\n",
    "# helper to compute NN outputs from raw features\n",
    "def nn_outputs_from_raw(model_nn, X_raw_np):\n",
    "    X_std = scaler.transform(X_raw_np)                     \n",
    "    with torch.no_grad():\n",
    "        X_t = torch.tensor(X_std, dtype=torch.float32, device=device)\n",
    "        y_hat = model_nn(X_t).cpu().numpy()               \n",
    "    return y_hat\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    report = reports[i]\n",
    "    model_name = element[1]\n",
    "    model = element[0]\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", report[\"accuracy\"])\n",
    "        mlflow.log_metric(\"recall_class_0\", report[\"0\"][\"recall\"])\n",
    "        mlflow.log_metric(\"recall_class_1\", report[\"1\"][\"recall\"])\n",
    "        mlflow.log_metric(\"f1_score_macro\", report[\"macro avg\"][\"f1-score\"])\n",
    "        mlflow.log_metric(\"f1_score_weighted\", report[\"weighted avg\"][\"f1-score\"])\n",
    "        \n",
    "        if \"XGB\" in model_name:\n",
    "            y_example = model.predict_proba(X_example)\n",
    "            signature = infer_signature(X_example, y_example)\n",
    "            mlflow.xgboost.log_model(model, artifact_path=\"model\", signature=signature, input_example=X_example)\n",
    "        elif \"Neural\" in model_name:\n",
    "            y_example_nn = nn_outputs_from_raw(model, X_example_nn)\n",
    "            signature = infer_signature(X_example_nn, y_example_nn)\n",
    "            mlflow.pytorch.log_model(model, artifact_path=\"model\", signature=signature, input_example=X_example_nn)\n",
    "        else:\n",
    "            y_example = model.predict_proba(X_example)\n",
    "            signature = infer_signature(X_example, y_example)\n",
    "            mlflow.sklearn.log_model(model, artifact_path=\"model\", signature=signature, input_example=X_example)"
   ],
   "id": "f30a03a9f272d30a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf26c9e5575d46ce8c45fb150be4f93f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/02 19:24:35 INFO mlflow.tracking._tracking_service.client: 🏃 View run Logistic Regression at: http://127.0.0.1:5000/#/experiments/361620438468430575/runs/55c4cf0a42724ae29f76586e3614b7be.\n",
      "2025/10/02 19:24:35 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/361620438468430575.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "850e0bd46adf4659a41450675ad60c36"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/02 19:24:45 INFO mlflow.tracking._tracking_service.client: 🏃 View run Random Forest at: http://127.0.0.1:5000/#/experiments/361620438468430575/runs/01cdd2afdb0641019b7aec32d1bcdc95.\n",
      "2025/10/02 19:24:45 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/361620438468430575.\n",
      "C:\\Users\\Igors\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [19:24:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "76b6b1cc8f674edfac232c53e9923ba7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/02 19:24:51 INFO mlflow.tracking._tracking_service.client: 🏃 View run XGBoost at: http://127.0.0.1:5000/#/experiments/361620438468430575/runs/e2107bc5416448bf9e9d918e7938b1d1.\n",
      "2025/10/02 19:24:51 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/361620438468430575.\n",
      "C:\\Users\\Igors\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [19:24:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e640b1a558b04747b17310d46b556452"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/02 19:24:56 INFO mlflow.tracking._tracking_service.client: 🏃 View run XGBoost with SMOTETomek at: http://127.0.0.1:5000/#/experiments/361620438468430575/runs/d2f7c17ea4d64b92bf65c57385d82383.\n",
      "2025/10/02 19:24:56 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/361620438468430575.\n",
      "2025/10/02 19:24:57 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/10/02 19:25:04 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01d7a260e49b456992182741e8f68f91"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/02 19:25:05 INFO mlflow.tracking._tracking_service.client: 🏃 View run Neural Network at: http://127.0.0.1:5000/#/experiments/361620438468430575/runs/e6c9981247dc4466b6635b2b693e7be7.\n",
      "2025/10/02 19:25:05 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/361620438468430575.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we register the best model (XGBoost with SMOTETomek) in the MLflow Model Registry and give the \"champion\" alias.",
   "id": "b0a220f3f087b7f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T18:29:28.756488Z",
     "start_time": "2025-10-02T18:29:27.416485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "model_name = \"XGBoost with SMOTETomek\"\n",
    "run_id = input(\"Enter Run ID:\")\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "result = mlflow.register_model(model_uri, model_name)\n",
    "# 6d90500db1fa4139a38c885c1804d32f\n",
    "\n",
    "client = MlflowClient()\n",
    "client.set_registered_model_alias(model_name, \"champion\", result.version)"
   ],
   "id": "3c795ab14aa2e23c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'XGBoost with SMOTETomek' already exists. Creating a new version of this model...\n",
      "2025/10/02 19:29:28 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBoost with SMOTETomek, version 1\n",
      "Created version '1' of model 'XGBoost with SMOTETomek'.\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we load the model.",
   "id": "6f0b1845de8b61b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T18:29:48.043982Z",
     "start_time": "2025-10-02T18:29:47.789861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"XGBoost with SMOTETomek\"\n",
    "model_version = 1\n",
    "model_uri = f\"models:/{model_name}@champion\"\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
    "y_pred = loaded_model.predict(X_test)"
   ],
   "id": "157ed3f8b0cc29d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e276de3d1a064c23aedb57fd55725c7a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
